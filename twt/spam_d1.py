# -*- coding: utf-8 -*-
"""spam-D1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eFBU3lPAuyj3dyAQqvhCQN3oOlZUMw4U

**Detection of Social Network Spam Based on Improved Machine Learning**

1. Import Libraries
"""

import pandas as pd
from sklearn import model_selection
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import model_selection
from scipy import stats
import joblib

"""2. Import dataset"""

df = pd.read_csv("dataset_1.csv")

"""Display Heads"""

df.head(2)

"""Describe the dataset"""

df.describe()

"""Display information of the dataset"""

df.info

"""Display the shape (No. of rows and columns) of the dataset"""

df.shape

"""Check the null values in the dataset"""

df.isnull().sum()

"""Print number of Features and no of samples"""

print('Number of features: {}'.format(df.shape[1]))
print('Number of examples: {}'.format(df.shape[0]))

"""**3. Data Visualization**

**Scatter Plot**

1. account_age VS no_tweets
"""

import matplotlib.pyplot as plt
# Create another figure
plt.figure(figsize=(9, 7))

# Scatter with postivie examples
plt.scatter(df.account_age[df.label =="spammer"],
            df.no_tweets[df.label=="spammer"],
            c="salmon")

# Scatter with negative examples
plt.scatter(df.account_age[df.label =="non-spammer"],
            df.no_tweets[df.label =="non-spammer"],
            c="lightblue")

# Add some helpful info
plt.title("Spam Detection account_age VS no_tweets")
plt.xlabel("account_age")
plt.ylabel("no_tweets")
plt.legend(["spammer", "non-spammer"]);

"""2. account_age VS no_tweets

3. account_age VS no_tweets

**Correlation Matrix**
"""

# Let's make our correlation matrix a little prettier
import seaborn as sns
corr_matrix = df.corr()
fig, ax = plt.subplots(figsize=(15, 15))
ax = sns.heatmap(corr_matrix,
                 annot=True,
                 linewidths=0.5,
                 fmt=".3f",
                 cmap="YlGnBu");
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5)

"""Count Number Positive and Negative samples"""

print(df['label'].value_counts())

"""**4. Dataset Splitting**"""

def read_dataset(filename):
    return model_selection.train_test_split(df.drop(['label'], axis=1), df["label"], train_size=0.8)

Xtrain, Xtest, Ytrain, Ytest = read_dataset(df)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

def print_score(clf, X_train, y_train, X_test, y_test, train=True):
    if train:
        pred = clf.predict(X_train)
        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))
        print("Train Result:\n================================================")
        print(f"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%")
        print("_______________________________________________")
        print(f"CLASSIFICATION REPORT:\n{clf_report}")
        print("_______________________________________________")
        print(f"Confusion Matrix: \n {confusion_matrix(y_train, pred)}\n")
        
    elif train==False:
        pred = clf.predict(X_test)
        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))
        print("Test Result:\n================================================")        
        print(f"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%")
        print("_______________________________________________")
        print(f"CLASSIFICATION REPORT:\n{clf_report}")
        print("_______________________________________________")
        print(f"Confusion Matrix: \n {confusion_matrix(y_test, pred)}\n")

"""**5. Claasification using Machine Learning Algorithm**

**A. SVM**
"""

from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler


svm_clf = make_pipeline(StandardScaler(), SVC())
svm_clf.fit(Xtrain, Ytrain)
predictions = svm_clf.predict(Xtest)

print('Predictions: \n', predictions)
print('\nConfusion matrix: \n', confusion_matrix(Ytest, predictions))
print('\nEvaluation metrics: \n',classification_report(Ytest, predictions))

print_score(svm_clf, Xtrain, Ytrain, Xtest, Ytest, train=True)
print_score(svm_clf, Xtrain, Ytrain, Xtest, Ytest, train=False)
joblib.dump(svm_clf, 'svm_clf.sav')

"""**B. KNN**"""

from sklearn.neighbors import KNeighborsClassifier

neigh = KNeighborsClassifier(n_neighbors=10, weights='distance', p=1)
clf_knn = make_pipeline(StandardScaler(), neigh)
clf_knn.fit(Xtrain, Ytrain)
predictions = clf_knn.predict(Xtest)

print('Predictions: \n', predictions)
print('\nConfusion matrix: \n', confusion_matrix(Ytest, predictions))
print('\nEvaluation metrics: \n',classification_report(Ytest, predictions))

print_score(clf_knn, Xtrain, Ytrain, Xtest, Ytest, train=True)
print_score(clf_knn, Xtrain, Ytrain, Xtest, Ytest, train=False)

joblib.dump(clf_knn, 'clf_knn.sav')

"""**C. Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

tree_clf = DecisionTreeClassifier(random_state=42)
tree_clf.fit(Xtrain, Ytrain)

print('Predictions: \n', predictions)
print('\nConfusion matrix: \n', confusion_matrix(Ytest, predictions))
print('\nEvaluation metrics: \n',classification_report(Ytest, predictions))

print_score(tree_clf, Xtrain, Ytrain, Xtest, Ytest, train=True)
print_score(tree_clf, Xtrain, Ytrain, Xtest, Ytest, train=False)

joblib.dump(tree_clf, 'clf_dt.sav')

"""**D. Random Forest**"""

from sklearn.ensemble import RandomForestClassifier
rand_for = RandomForestClassifier(criterion='entropy', n_estimators=100)
clf_rf = make_pipeline(StandardScaler(), rand_for)
clf_rf.fit(Xtrain, Ytrain)
predictions = clf_rf.predict(Xtest)

print('Predictions: \n', predictions)
print('\nConfusion matrix: \n', confusion_matrix(Ytest, predictions))
print('\nEvaluation metrics: \n',classification_report(Ytest, predictions))

print_score(clf_rf, Xtrain, Ytrain, Xtest, Ytest, train=True)
print_score(clf_rf, Xtrain, Ytrain, Xtest, Ytest, train=False)

joblib.dump(clf_rf, 'clf_rf.sav')